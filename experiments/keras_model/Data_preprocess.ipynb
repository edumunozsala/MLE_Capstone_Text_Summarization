{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Problem Statement\n",
    "\n",
    "Customer reviews can often be long and descriptive. Analyzing these reviews manually, as you can imagine, is really time-consuming. This is where the brilliance of Natural Language Processing can be applied to generate a summary for long reviews.\n",
    "\n",
    "We will be working on a really cool dataset. Our objective here is to generate a summary for the Amazon Fine Food reviews using the abstraction-based approach we learned about above. You can download the dataset from[ here ](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
    "\n",
    "It’s time to fire up our Jupyter notebooks! Let’s dive into the implementation details right away.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first time you need to install beautifulsoup4\n",
    "#!pip install --user beautifulsoup4\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datafiles from GS\n",
    "import os, shutil\n",
    "DATADIR='data'\n",
    "os.environ['DATA'] = DATADIR\n",
    "\n",
    "shutil.rmtree(DATADIR, ignore_errors=True)\n",
    "os.makedirs(DATADIR)\n",
    "\n",
    "#Copy datafile from GS bucket\n",
    "#!gsutil cp gs://mlend_text_summarization/data/amazon-fine-food-reviews/Reviews_mini.csv ${DATADIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://mlend_text_summarization/data/amazon-fine-food-reviews/Reviews_mini.csv...\n",
      "- [1 files][ 48.9 MiB/ 48.9 MiB]                                                \n",
      "Operation completed over 1 objects/48.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp gs://mlend_text_summarization/data/amazon-fine-food-reviews/Reviews_mini.csv ${DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data/Reviews_mini.csv\",nrows=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 959 entries, 0 to 4998\n",
      "Data columns (total 10 columns):\n",
      "Id                        959 non-null object\n",
      "ProductId                 959 non-null object\n",
      "UserId                    959 non-null object\n",
      "ProfileName               959 non-null object\n",
      "HelpfulnessNumerator      959 non-null float64\n",
      "HelpfulnessDenominator    959 non-null float64\n",
      "Score                     959 non-null float64\n",
      "Time                      959 non-null float64\n",
      "Summary                   959 non-null object\n",
      "Text                      959 non-null object\n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Performing basic preprocessing steps is very important before we get to the model building part. Using messy and uncleaned text data is a potentially disastrous move. So in this step, we will drop all the unwanted symbols, characters, etc. from the text that do not affect the objective of our problem.\n",
    "\n",
    "Here is the dictionary that we will use for expanding the contractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "8.Remove short words\n",
    "\n",
    "Let’s define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'right mostly sprouting cats eat grass love rotate around wheatgrass rye',\n",
       " 'healthy dog food good digestion also good small puppies dog eats required amount every feeding',\n",
       " 'love eating good watching tv looking movies sweet like transfer zip lock baggie stay fresh take time eating']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'cough medicine',\n",
       " 'yay barley',\n",
       " 'healthy dog food',\n",
       " 'poor taste',\n",
       " 'love it',\n",
       " 'home delivered twizlers',\n",
       " 'delicious product',\n",
       " 'twizzlers',\n",
       " 'great bargain for the price']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Understanding the distribution of the sequences\n",
    "\n",
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. We can fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
    "\n",
    "Let us understand the proportion of the length of summaries below 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874869655891554\n"
     ]
    }
   ],
   "source": [
    "summary_length=10\n",
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=summary_length):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 94% of the summaries have length below 8. So, we can fix maximum length of summary to 8.\n",
    "\n",
    "Let us fix the maximum length of review to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=40\n",
    "max_summary_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select the reviews and summaries whose length falls below or equal to **max_text_len** and **max_summary_len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cough medicine</td>\n",
       "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yay barley</td>\n",
       "      <td>right mostly sprouting cats eat grass love rotate around wheatgrass rye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>healthy dog food</td>\n",
       "      <td>healthy dog food good digestion also good small puppies dog eats required amount every feeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poor taste</td>\n",
       "      <td>love eating good watching tv looking movies sweet like transfer zip lock baggie stay fresh take time eating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 summary  \\\n",
       "0  good quality dog food   \n",
       "1         cough medicine   \n",
       "2             yay barley   \n",
       "3       healthy dog food   \n",
       "4             poor taste   \n",
       "\n",
       "                                                                                                                                                                   text  \n",
       "0  bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better  \n",
       "1                                           looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal  \n",
       "2                                                                                               right mostly sprouting cats eat grass love rotate around wheatgrass rye  \n",
       "3                                                                        healthy dog food good digestion also good small puppies dog eats required amount every feeding  \n",
       "4                                                           love eating good watching tv looking movies sweet like transfer zip lock baggie stay fresh take time eating  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data preprocessed and cleaned\n",
    "Create a file for training and a file for evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth dataset:  914\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(10)\n",
    "print('Lenth dataset: ',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776\n"
     ]
    }
   ],
   "source": [
    "training_size = int(len(df)*0.85)\n",
    "print(training_size)\n",
    "df.iloc[:training_size,:].to_csv('data/train.csv',sep=',')\n",
    "df.iloc[training_size:,:].to_csv('data/validation.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the train and validation dataset to GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data/train.csv [Content-Type=text/csv]...\n",
      "/ [1 files][103.4 KiB/103.4 KiB]                                                \n",
      "Operation completed over 1 objects/103.4 KiB.                                    \n",
      "Copying file://data/validation.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 17.5 KiB/ 17.5 KiB]                                                \n",
      "Operation completed over 1 objects/17.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp data/train.csv gs://mlend_text_summarization/data/amazon-fine-food-reviews\n",
    "gsutil cp data/validation.csv gs://mlend_text_summarization/data/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
