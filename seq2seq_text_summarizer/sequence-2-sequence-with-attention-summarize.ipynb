{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summarization using machine learning techniques\n",
    "\n",
    "## A sequence-to-sequence model using an Encoder-Decoder with Attention\n",
    "\n",
    "The encoder-decoder model for recurrent neural networks is an architecture for sequence-to-sequence prediction problems. It comprised two parts:\n",
    "-\t**Encoder**: The encoder is responsible for stepping through the input time steps, read the input words one by one and encoding the entire sequence into a fixed length vector called a context vector.\n",
    "-\t**Decoder**: The decoder is responsible for stepping through the output time steps while reading from the context vector, extracting the words one by one.\n",
    "The trouble with seq2seq is that the only information that the decoder receives from the encoder is the last encoder hidden state which is like a numerical summary of an input sequence. So, for a long input text, we expect the decoder to use just this one vector representation to output a translation. This might lead to catastrophic forgetting.\n",
    "\n",
    "To solve this problem, the attention mechanism was developed. **Attention** is proposed as a method to both align and translate. It identifies which parts of the input sequence are relevant to each word in the output (alignment) and use that relevant information to select the right output (translation). So instead of encoding the input sequence into a single fixed context vector (reason for the mentioned bad performance), the attention model develops a context vector that is filtered specifically for each output time step [11]. Attention provides the decoder with information from every encoder hidden state. With this setting, the model can selectively focus on useful parts of the input sequence and hence, learn the alignment between them.\n",
    "\n",
    "In the next few sections we will go through the whole process: Load the datasets and vector representation, build the vocabulary, define the encoder, decoder and attention mechanism. Then we will code the train stage, iterating over the datasets, and finally we will make the predictions for the validation dataset to get the value of the metrics of interest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "#Import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#Import libraries for text processing\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#Import some utils\n",
    "from io import open\n",
    "import unicodedata\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#Import the pytorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the library to calculate the evaluations metrics: ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from rouge) (1.12.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "#Import library to calculate the evaluation metric\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters with the train and validation filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv'\n",
    "valid_path = '/kaggle/input/cleaned-news-summary/cl_valid_news_summary_more.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are reading just a subset of 10,000 rows from the validation datasets to reduce the runnig time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop null and duplicates, Total rows: 83589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>paytm raises 1 4 billion softbank largest funding</td>\n",
       "      <td>digital payments startup paytm raised 1 4 bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>petrol price cut 창 per litre daily revision st...</td>\n",
       "      <td>oil companies thursday reduced petrol price 창 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>army plans deploy women officers cyber warfare</td>\n",
       "      <td>indian army announced plans deploy women offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>uday chopra confirms yrf produce jessica chast...</td>\n",
       "      <td>yash raj films ceo uday chopra confirmed los a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mulayam yadav contest 2019 polls mainpuri sp l...</td>\n",
       "      <td>senior samajwadi party leader ram gopal yadav ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  paytm raises 1 4 billion softbank largest funding   \n",
       "1  petrol price cut 창 per litre daily revision st...   \n",
       "2     army plans deploy women officers cyber warfare   \n",
       "3  uday chopra confirms yrf produce jessica chast...   \n",
       "4  mulayam yadav contest 2019 polls mainpuri sp l...   \n",
       "\n",
       "                                                text  \n",
       "0  digital payments startup paytm raised 1 4 bill...  \n",
       "1  oil companies thursday reduced petrol price 창 ...  \n",
       "2  indian army announced plans deploy women offic...  \n",
       "3  yash raj films ceo uday chopra confirmed los a...  \n",
       "4  senior samajwadi party leader ram gopal yadav ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "data = pd.read_csv(data_path,encoding='utf-8')\n",
    "#Drop rows with duplicate values in the text column\n",
    "data.drop_duplicates(subset=[\"text\"],inplace=True)\n",
    "#Drop rows with null values in the text variable\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "# we are using the text variable as the summary and the ctext as the source text\n",
    "print('Drop null and duplicates, Total rows:', len(data))\n",
    "# Rename the columns\n",
    "data.columns = ['summary','text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop null and duplicates, Total rows: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>govt forms sit ryan murder case cbse seeks saf...</td>\n",
       "      <td>hrd ministry formed threemember special invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>indrani asks furniture jewellery divorce report</td>\n",
       "      <td>letter written jail sheena bora murder accused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ed raids 35 premises nirav modi 창 assets seized</td>\n",
       "      <td>enforcement directorate ed friday conducted se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>japan admits 1st death 2011 fukushima nuclear ...</td>\n",
       "      <td>japan acknowledged first time worker died radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>entire village germany auctioned</td>\n",
       "      <td>entire village germany auctioned weekend bids ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  govt forms sit ryan murder case cbse seeks saf...   \n",
       "1    indrani asks furniture jewellery divorce report   \n",
       "2    ed raids 35 premises nirav modi 창 assets seized   \n",
       "3  japan admits 1st death 2011 fukushima nuclear ...   \n",
       "4                   entire village germany auctioned   \n",
       "\n",
       "                                                text  \n",
       "0  hrd ministry formed threemember special invest...  \n",
       "1  letter written jail sheena bora murder accused...  \n",
       "2  enforcement directorate ed friday conducted se...  \n",
       "3  japan acknowledged first time worker died radi...  \n",
       "4  entire village germany auctioned weekend bids ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "valid_dataset = pd.read_csv(valid_path,encoding='utf-8', nrows=10000)\n",
    "#Drop rows with duplicate values in the text column\n",
    "valid_dataset.drop_duplicates(subset=[\"text\"],inplace=True)\n",
    "#Drop rows with null values in the text variable\n",
    "valid_dataset.dropna(inplace=True)\n",
    "valid_dataset.reset_index(drop=True,inplace=True)\n",
    "# we are using the text variable as the summary and the ctext as the source text\n",
    "print('Drop null and duplicates, Total rows:', len(valid_dataset))\n",
    "# Rename the columns\n",
    "valid_dataset.columns = ['summary','text']\n",
    "valid_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "We create a mapping from common contractions to it expanded form, we will use it later to clean and process the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess the data (but it could be processed previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    ''' Function to clean the input text: convert to lowercase, expand the contractions, remove the stopwords,\n",
    "        remove punctuations\n",
    "    '''\n",
    "\n",
    "    text = text.lower() # lowercase\n",
    "    text = text.split() # convert have'nt -> have not\n",
    "    \n",
    "    for i in range(len(text)): # For every token or word in the text\n",
    "        word = text[i]\n",
    "        if word in contraction_mapping:\n",
    "            text[i] = contraction_mapping[word] # Expand the contractions\n",
    "            \n",
    "    text = \" \".join(text) # Rejoin the word to a sentence\n",
    "    text = text.split() # Split the text into words\n",
    "    newtext = []\n",
    "    for word in text: # For every token or word in the text\n",
    "        if word not in stop_words:\n",
    "            newtext.append(word) #Include only the non stopwords\n",
    "    text = \" \".join(newtext)\n",
    "    text = text.replace(\"'s\",'') # Expand contractions, convert your's -> your\n",
    "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
    "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
    "    text = re.sub(r'\\.',' . ',text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the cleaning and preprocess function to remove symbols, especial characters, stopwords,.. on the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].apply(lambda x:preprocess(x))\n",
    "data['text'] = data['text'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset['summary'] = data['summary'].apply(lambda x:preprocess(x))\n",
    "valid_dataset['text'] = data['text'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a example of the cleaned text and summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tamil nadu government claimed reports plastic rice sold state spread panic among people fake comes food safety department carried inspections 50 shops district tanjore ensure incidents plastic rice'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'][20]\n",
    "data['text'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our pandas dataframe to two variables, x and y, for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony chapron french referee kicked footballer sending ligue 1 game handed threemonth ban three months suspended ban ligue 1 chapron apologised actions following day incident called reaction clumsy inappropriate\n",
      "french referee kicked footballer banned 3 months\n"
     ]
    }
   ],
   "source": [
    "x = data['text']\n",
    "y = data['summary']\n",
    "print(x[50],y[50],sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a global variable to indicate if there is a GPU available for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and create the vocabularies\n",
    "\n",
    "Now we create a Vocab (vocabulary) Class to store the vocabulary, the mapping between words and its numeric representation and functions to add words and sentences to the vocabulary. There is also some function to transform a sentence to its vector representation and to transform the representation to a Torch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        ''' Add every word in a sentence to the vocabulary '''\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        ''' Add a word to the vocabulary'''\n",
    "        if word not in self.word2index:\n",
    "            #Include the word in the mapping from word to index\n",
    "            self.word2index[word] = self.n_words\n",
    "            #Set the count of ocurrencies of the word to 1\n",
    "            self.word2count[word] = 1\n",
    "            # Include the word in the indexes\n",
    "            self.index2word[self.n_words] = word\n",
    "            # Increment by 1 the number of words\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def save_to_file(self, filename):\n",
    "        ''' Save the Vocab object to a file'''\n",
    "        with open(filename,'wb') as f:\n",
    "            pickle.dump(self,f) \n",
    "\n",
    "def load_vocab(filename):\n",
    "    ''' Load a Vocab instance from a file'''\n",
    "    with open(filename,'rb') as f:\n",
    "        v = pickle.load(f)\n",
    "    return v\n",
    "\n",
    "def read_vocabs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Vocab(summary)\n",
    "        output_lang = Vocab(text)\n",
    "    else:\n",
    "        input_lang = Vocab(text)\n",
    "        output_lang = Vocab(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_vocabs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to build a vocabulary for each dataset, training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 83589 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "0        digital payments startup paytm raised 1 4 bill...\n",
      "1        oil companies thursday reduced petrol price  d...\n",
      "2        indian army announced plans deploy women offic...\n",
      "3        yash raj films ceo uday chopra confirmed los a...\n",
      "4        senior samajwadi party leader ram gopal yadav ...\n",
      "                               ...                        \n",
      "83584    north korea estimated 60 nuclear weapons south...\n",
      "83585    former west indies captain sir viv richards 18...\n",
      "83586    malikaa marathe 13yearold national tennis cham...\n",
      "83587    usbased software supplier ebixs indian subsidi...\n",
      "83588    exaustralia cricketer dean jones said playing ...\n",
      "Name: text, Length: 83589, dtype: object 95677\n",
      "0        paytm raises 1 4 billion softbank largest funding\n",
      "1        petrol price cut  per litre daily revision starts\n",
      "2           army plans deploy women officers cyber warfare\n",
      "3        uday chopra confirms yrf produce jessica chast...\n",
      "4        mulayam yadav contest 2019 polls mainpuri sp l...\n",
      "                               ...                        \n",
      "83584           n korea estimated 60 nuclear weapons korea\n",
      "83585        viv richards played greatest odi innings time\n",
      "83586      girl almost lost eyesight indias top u14 player\n",
      "83587    ebix india unit buys 67 stake logistics startu...\n",
      "83588              one die dean jones indias 2 odis 2 days\n",
      "Name: summary, Length: 83589, dtype: object 39210\n",
      "['government wednesday confirmed introduction new  notes rbi first time immediate date specified new notes could reportedly introduced september  note fill missing middle even new currency circulation reached 84 predemonetisation level sbi said earlier', 'government confirms introduction new  notes']\n"
     ]
    }
   ],
   "source": [
    "# Create the vocabularies of the inout and output data and return the data in pairs of (source text, summary)\n",
    "input_lang, output_lang, pairs = prepare_data( x, y , False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important parameter we need to set is the maximum length of a sequence of text. We find out the max length in the sourfe texts and the summaries and set the max length to that value plus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length of Texts:  60 Max Length of Summaries:  53\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "len_x_tr=[]\n",
    "len_y_tr=[]\n",
    "# For every pair Text, summary on the training dataset\n",
    "for i in pairs:\n",
    "    len_x_tr.append(len(i[0].split(' '))) # Get the count of words for the soure text\n",
    "    len_y_tr.append(len(i[1].split(' '))) # Get the count of words for the summary\n",
    "    \n",
    "# \n",
    "x_test = valid_dataset['text'].values\n",
    "y_test = valid_dataset['summary'].values\n",
    "\n",
    "len_x_val=[]\n",
    "len_y_val=[]\n",
    "# For every pair Text, summary\n",
    "for i in range(len(x_test)):\n",
    "    len_x_val.append(len(x_test[i].split(' '))) # Get the count of words for the soure text\n",
    "    len_y_val.append(len(y_test[i].split(' '))) # Get the count of words for the summary\n",
    "\n",
    "print('Max Length of Texts: ', max(len_x_tr), 'Max Length of Summaries: ',max(len_x_val))\n",
    "# Set the global variable MAX LENGTH\n",
    "MAX_LENGTH = max(max(len_x_tr), max(len_y_tr), max(len_x_val), max(len_y_val), )+1\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "First, we define the Encoder component of our Sequence-to-Sequence model. It will be comprised by an embedding layer and a GRU layer (Gate Recurrent Unit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    ''' Define an encoder in a seq2seq architecture'''\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        ''' Initialize tyhe encoder instance defining its parameters:\n",
    "            Input:\n",
    "                - input_size: the size of the vocabulary\n",
    "                - hidden:size: size of the hidden layer\n",
    "        '''\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Create the embedding layer of size (vocabulary length, hidden_size) \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Create a GRU layer\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        ''' Run a Forward pass of the encoder to return outputs\n",
    "            Input:\n",
    "                Input: a tensor element (integer) representing the next word in the sentence\n",
    "                hidden: a tensor, the previous hidden state of the encoder\n",
    "        '''\n",
    "        # Get the embedding of the input\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        \n",
    "        # Apply a forward step of the GRU returning the output features and\n",
    "        # the hidden state of the actual time step\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        ''' Initialize the hidden state of the encoder, tensor of zeros'''\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the decoder with attention component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    ''' Define a decoder with atention in a seq2seq architecture'''\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        ''' Initialize the decoder instance defining its parameters:\n",
    "            Input:\n",
    "                - hidden_size:size: size of the hidden layer (Hyperparameter)\n",
    "                - output_size: the size of the vocabulary of the output summary\n",
    "                - dropout_p: dropout probability to apply\n",
    "                - max_length: max length (number of words) of an output or summary\n",
    "        '''\n",
    "\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        # Set parameters of the decoder\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        #Create an embedding layer for the input (output vocabulary, hidden size)\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        # Create some linear layers to build the attention mechanism\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        # A dropout layer\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        # A GRU layer\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        # A Fully-connected layer\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        ''' Run a Forward pass of the decoder to return outputs\n",
    "            Input:\n",
    "                Input: a tensor element (integer) representing the previous output of the decoder\n",
    "                hidden: a tensor, the previous hidden state of the decoder\n",
    "                Encoder outputs: a tensor, outputs of the encoder\n",
    "        '''\n",
    "        \n",
    "        #Get the embedding representation of the input\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Apply dropout \n",
    "        embedded = self.dropout(embedded)\n",
    "        #Calculate the attention weights of the attention mechanism using the encoder states\n",
    "        #in previous time steps\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        #Calculate the context vectors fo the attention mechanism using the attention weights\n",
    "        # and the encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # Apply a forward pass to the GRU layer of the decider using the output from the attention\n",
    "        # as input and the hidden state\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        # return the output features, the hidden state and the attention weights\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        ''' Initialize the hidden state of the encoder, tensor of zeros'''\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the steps of the training process\n",
    "\n",
    "First, we create functions to help us to handle and transform the text input data to tensor datatype requiered to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    ''' Transform a sentence in string format to a list of indexes or integers.\n",
    "            The model need to be feeded with numbers, not characters\n",
    "            Input:\n",
    "                - sentence: a string\n",
    "            Output:\n",
    "                - a list of integers, the representation of the sentence in the vector space.\n",
    "    '''\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    ''' Transform a sentence in string format to tensor of indexes or integers.\n",
    "            Out pytorch model work with tensor objects\n",
    "            Input:\n",
    "                - sentence: a string\n",
    "            Output:\n",
    "                - a tensor of integers, the representation of the sentence in the vector space.\n",
    "    '''\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    ''' Convert a pair of text data (source text, summary) to tensors\n",
    "        Input:\n",
    "        - pair: tuple of strings, the source text and its summary\n",
    "        Output:\n",
    "        - tuple of tensors, the input tensor and the outout one\n",
    "    '''\n",
    "    # Convert the source text to the input tensor\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    # Convert the summary to the output tensor\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply Teacher forcing, a method for quickly and efficiently training recurrent neural network models that use the ground truth from a prior time step as input, that is, using the actual or expected output from the training dataset at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network \n",
    "\n",
    "First we define the probability of applying teacher forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function execute a training step where we provide an input and target tensor and apply the algorithm on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    ''' Run all the steps in the training phase of a batch of examples\n",
    "        Input:\n",
    "        - input_tensor: a tensor, vector representation of the input text\n",
    "        - target_tensor: a tensor, vector representation of the expect or labelled output or summary\n",
    "        - encoder: a Class Encoder object, the encoder\n",
    "        - decoder: a Class AttnDecoder object, the decoder\n",
    "        - encoder_optimizer: a torch optimizer, the optimizer of the encoder\n",
    "        - decoer_optimizer: a torch optimizer, the optimizer of the decoder\n",
    "        - criterion: a pytoch loss function\n",
    "        - max_length: an integer, maximun length of an output\n",
    "    '''\n",
    "    #Init the encoder hidden state\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    # Reset the optimizer\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Set the length if the source text and the summary\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    # Create the initial encoder output, all zeros\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    # For every token in the source text or inout\n",
    "    for ei in range(input_length):\n",
    "        # Forward pass of the encoder to get the encoder output and hidden state\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    # Set the initial decoder input as the SOS token\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    #Set the initial decoder hidden state equals to the last encoder hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Active teacher forcing with probability teacher_forcing_ratio \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            # Forward pass of the decoder returning the decoder output, hidden state and context vector\n",
    "            # of the attention mechanism\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Increment the loss function by the loss of the decoder output in the actual time step\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # Forward pass of the decoder returning the decoder output, hidden state and context vector\n",
    "            # of the attention mechanism\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "             # Select the decoder output with the highest probability\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            # Increment the loss function by the loss of the decoder output in the actual time step\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # Stop training if the EOS token is returned\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "   # Apply the backward pass to calculate and propagate the loss\n",
    "    loss.backward()\n",
    "    # Apply a step of the optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    # Return the final loss\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpers function to show the progress and losses during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    ''' Return the seconds, s, to a string in the format: Xm Ys'''\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    ''' Return '''\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    ''' Plot the points in a line graph to show a training metric'''\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function describes the training process, iterating over the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    ''' Train a encoder-decoder model on the input x for n_iters iterations\n",
    "        Input:\n",
    "        - encoder: a Class Encoder object, the encoder\n",
    "        - decoder: a Class AttnDecoder object, the decoder\n",
    "        - x: array of strings, source texts of the training dataset\n",
    "        - y: array of strings, target texts or summaries of the training dataset\n",
    "        - vocab_input: a Vocab Class object, vocabulary of the source texts\n",
    "        - vocab_output: a Vocab Class object, vocabulary of the target texts\n",
    "        - n_iters: integer, number of iterations\n",
    "        - print_every: integer, print the progress every print_every iteration\n",
    "        - plot_every: integer, plot the losses every plot_every iteration\n",
    "        - learning_rate: float, learning rate\n",
    "    '''\n",
    "\n",
    "    print(\"Training....\")\n",
    "    # Get the current time\n",
    "    start = time.time()\n",
    "    # Initialize variables for progress tracking\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    # Create the optimizer for the encoder and the decoder\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # Extract the training set randomly for all the iterations\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    # Set the function loss to apply\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if iter% 1000 == 0:\n",
    "            print(iter,\"/\",n_iters + 1) # Plot progress\n",
    "            \n",
    "        # Get the next pair of source text and target to train on\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        # Train on the pair of data selected\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        # Set the variable to plot the progress\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            # Print the ETA and current loss\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            # Plot the current loss\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate or predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n",
    "    ''' Function to predict the summary of the source text sentence with a max length\n",
    "        Input:\n",
    "        - encoder: a Class Encoder object, the encoder\n",
    "        - decoder: a Class AttnDecoder object, the decoder\n",
    "        - vocab_input: a Vocab Class object, vocabulary of the source texts\n",
    "        - vocab_output: a Vocab Class object, vocabulary of the target texts\n",
    "        - sentence: string, source text to predict\n",
    "\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        # Get the tensor of the source text\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        # Calculate the length of the source text\n",
    "        input_length = input_tensor.size()[0]\n",
    "        # Set the initial hidden state of the encoder\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        # Set the initial encoder outputs\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        # For every word in the input\n",
    "        for ei in range(input_length):\n",
    "            # Forward pass of the encoder\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        # Set the initial input of the decoder \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        # Set the initial hidden state of the decoder to the hidden state of the decoder in the last time step\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        # Set the initial context vectors of the decoder to zeros\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        # For every word or step in the output sequence\n",
    "        for di in range(max_length):\n",
    "            # Forward pass of the decoder\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Save the decoder attention vector of the step\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            # Get the element in the decoder output with the highest probability (the best output)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            # If the token returned is EOS then finish\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                # Append the token in the summary returned by the decoder\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            # Set the decoder input to the output selected\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will generate the predictions for a set of source texts to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(x_test, encoder, decoder, input_vocab, output_vocab, max_length, print_every=20):\n",
    "    ''' Generate the predicted summaries of the source texts on x_test\n",
    "        Input:\n",
    "        - x_test: list of strings, the source texts\n",
    "        - encoder: a Class Encoder object, the encoder\n",
    "        - decoder: a Class AttnDecoder object, the decoder\n",
    "        - input_vocab: a Vocab Class object, vocabulary of the source texts\n",
    "        - output_vocab: a Vocab Class object, vocabulary of the target texts\n",
    "        - max_length: integer, max length of the output summary\n",
    "        - print_every: integer, print progress every print_every iterations\n",
    "    '''\n",
    "    predicted_summaries = []\n",
    "    # Set a progress bar\n",
    "    #kbar = pkbar.Kbar(target=len(x_test), width=8)\n",
    "    # Para cada text or document in the validation dataset\n",
    "    for i,doc in enumerate(x_test):\n",
    "        # Predict the summary for the document\n",
    "        #pred_summ = predict(doc,vocab,params,batch_size=1)\n",
    "        pred_summ,_ = predict(encoder, decoder, doc, input_vocab, output_vocab, max_length)\n",
    "        predicted_summaries.append(' '.join(pred_summ[:-1]))\n",
    "        #predicted_summaries.append(' '.join(pred_summ))\n",
    "        \n",
    "        #if i%print_every==0:\n",
    "        #    kbar.update(i)\n",
    "            \n",
    "    # Set teh labeled summaries as the y_test variable, column summary of our dataset\n",
    "    return predicted_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = predict(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "It is time to train our model, setting the hidden size in 100, the iterations in 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "1000 / 75001\n",
      "2000 / 75001\n",
      "3000 / 75001\n",
      "4000 / 75001\n",
      "5000 / 75001\n",
      "3m 26s (- 48m 4s) (5000 6%) 7.0141\n",
      "6000 / 75001\n",
      "7000 / 75001\n",
      "8000 / 75001\n",
      "9000 / 75001\n",
      "10000 / 75001\n",
      "6m 51s (- 44m 33s) (10000 13%) 7.1869\n",
      "11000 / 75001\n",
      "12000 / 75001\n",
      "13000 / 75001\n",
      "14000 / 75001\n",
      "15000 / 75001\n",
      "10m 13s (- 40m 55s) (15000 20%) 7.0727\n",
      "16000 / 75001\n",
      "17000 / 75001\n",
      "18000 / 75001\n",
      "19000 / 75001\n",
      "20000 / 75001\n",
      "13m 38s (- 37m 31s) (20000 26%) 7.0824\n",
      "21000 / 75001\n",
      "22000 / 75001\n",
      "23000 / 75001\n",
      "24000 / 75001\n",
      "25000 / 75001\n",
      "17m 2s (- 34m 4s) (25000 33%) 7.0924\n",
      "26000 / 75001\n",
      "27000 / 75001\n",
      "28000 / 75001\n",
      "29000 / 75001\n",
      "30000 / 75001\n",
      "20m 25s (- 30m 37s) (30000 40%) 7.0620\n",
      "31000 / 75001\n",
      "32000 / 75001\n",
      "33000 / 75001\n",
      "34000 / 75001\n",
      "35000 / 75001\n",
      "23m 48s (- 27m 12s) (35000 46%) 6.9544\n",
      "36000 / 75001\n",
      "37000 / 75001\n",
      "38000 / 75001\n",
      "39000 / 75001\n",
      "40000 / 75001\n",
      "27m 11s (- 23m 47s) (40000 53%) 7.0051\n",
      "41000 / 75001\n",
      "42000 / 75001\n",
      "43000 / 75001\n",
      "44000 / 75001\n",
      "45000 / 75001\n",
      "30m 36s (- 20m 24s) (45000 60%) 6.9072\n",
      "46000 / 75001\n",
      "47000 / 75001\n",
      "48000 / 75001\n",
      "49000 / 75001\n",
      "50000 / 75001\n",
      "34m 0s (- 17m 0s) (50000 66%) 6.9554\n",
      "51000 / 75001\n",
      "52000 / 75001\n",
      "53000 / 75001\n",
      "54000 / 75001\n",
      "55000 / 75001\n",
      "37m 23s (- 13m 35s) (55000 73%) 6.8884\n",
      "56000 / 75001\n",
      "57000 / 75001\n",
      "58000 / 75001\n",
      "59000 / 75001\n",
      "60000 / 75001\n",
      "40m 48s (- 10m 12s) (60000 80%) 6.8129\n",
      "61000 / 75001\n",
      "62000 / 75001\n",
      "63000 / 75001\n",
      "64000 / 75001\n",
      "65000 / 75001\n",
      "44m 12s (- 6m 48s) (65000 86%) 6.7826\n",
      "66000 / 75001\n",
      "67000 / 75001\n",
      "68000 / 75001\n",
      "69000 / 75001\n",
      "70000 / 75001\n",
      "47m 37s (- 3m 24s) (70000 93%) 6.7500\n",
      "71000 / 75001\n",
      "72000 / 75001\n",
      "73000 / 75001\n",
      "74000 / 75001\n",
      "75000 / 75001\n",
      "51m 2s (- 0m 0s) (75000 100%) 6.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXe4FOX1x79nd2/h0ptIFVBAURCUoqKgoKhoLNHEFo1GY4k1+SWKMSbGRGPXJLYgRk2xxBI1oogdpSlI71WK0qXDLbvv74+Zd/add96Znd2de+/u9Xye5z53d2Z25kw773nPe95zSAgBhmEYpmERq28BGIZhmOhh5c4wDNMAYeXOMAzTAGHlzjAM0wBh5c4wDNMAYeXOMAzTAGHlzjAM0wBh5c4wDNMAYeXOMAzTAEnU14HbtGkjunbtWl+HZxiGKUpmzJixWQjRNtN29abcu3btiunTp9fX4RmGYYoSIvoqzHbslmEYhmmAsHJnGIZpgLByZxiGaYCwcmcYhmmAsHJnGIZpgGRU7kTUi4hmKX87iOgmw3bH2+vnE9EntSMuwzAME4aMoZBCiMUA+gEAEcUBrAPwX3UbImoB4HEApwghVhPRfrUgK8MwDBOSbN0yIwAsF0LocZYXAnhNCLEaAIQQG6MQLgw1yRT+M30NUikuF8gwDCPJVrmfD+AFw/KeAFoS0cdENIOILslftHA8/dlK3PzKHLw8Y01dHZJhGKbgCT1DlYhKAZwB4Faf/RwJy7JvBGAKEU0VQizR9nElgCsBoEuXLrnK7GLL7ioAwLY91ZHsj2EYpiGQjeV+KoAvhRAbDOvWAhgvhNgthNgMYCKAw/WNhBBjhBADhBAD2rbNmBohFEKwO4ZhGEYnG+V+AcwuGQB4A8BxRJQgogoAgwEszFe4MEjdTlQXR2MYhikOQrllbIV9EoCrlGVXA4AQ4kkhxEIiGg9gDoAUgLFCiHm1IK+/jGDtzjAMIwml3IUQewC01pY9qX2/H8D90YkWjvpyymzYsQ+bdlbisI7N60mC6Ni4Yx/+O3MdrhzaHcRdIIZpENRbyt+oqWudNOSeD1GTElh1z2l1e+Ba4IYXZ2Lqiq0Y2rMtDmnfrL7FYRgmAoo+/UB9jafWNKC4+l2VNQCAmmTDOSeG+a5T9Mo9iB37qrFzH4dIZiJmd3tSHHnEMA2GBuOWMdH3jgkA0CBcJ7WJ9GixcmeYhkPRW+7CZ0h14859nmXvL9iAN2aty/1YQuD3/5uPhd/syHkfUbOvOonlm3bltQ85iBqlal+zdQ9qkqkI98gwTDYUvXKX6FEeg+76wLPNFf+YjhtfnJXzMb7dU41nJq3CeX+bkvM+ouamF2dhxIOfYF91Mud9yEsX1YSwjTv24bj7PsKf3lkUyf4YhsmeBqPc65I9Vbkr0qiZtGwzAKCyJncrWfrcozK0N++yUkJI2RiGqXuKXrmbjE3dAv1g4QYnIiQfqm3tV1CRMhGEgMbsfUTlRpG++xjHzDNMvRFZsQ5724FElCSic6MXNYOcyuekpnwvf246vrUTjOVDtUH5FUxumzzEkLN7F2/YidVb9uQvii1LrOhNB4YpXjK+fkKIxUKIfkKIfrAyP+6BVqwDcAp53Avg3cilzBKTYV0VgVVabYgDr20j/k9vL0S/Oyfg5elrjA2JbNQEBJIpYWyAMiEN7N//bwGG3v9RHtJaJNlyZ5h6J6piHQBwPYBXAdRZoQ4gbTmresQU0jfiwXTlP5MCrKpJYd667YHHMv1O7yVEwc591Y6/+m8TV2Dbnmr86pU5mLlmm+9vkimBC5+aih63vZP18aLWwSnnnrByj5LJyzaj6+hxxkgwhtGJpFgHEXUEcDaAJz2/qGNen7kO67btDdzGFFly99sLcfpfP8PKzbudZYf/fgLufnshnpq4Ap8u3WRU7rURG37t8zNx0dhp2LKr0rV86y5/11JSCExbuTWn40VtYTtuGdbtkfL3SasAADNX+zfyDCOJqljHIwBuEUIkg6y12ijWIUkJy7K+6aVZaFFRErjt3qokmpa7t5llW8Vbd1ehW5vGAIDte6sxZuIKZ5vXrx3i2VdtWO4yjl4fuN1d5R0UdmLU8xAjeuXObpnaIBZxyCrTsMlmhmpQsY4BAF60FU0bAKOIqEYI8bq6kRBiDIAxADBgwIBInlC5k1RKOIo2U1WmvQEx4UH6yBRN8v7CDeixX1PEYsDB+0eTdEvWg9WVY9B55dPIRO+Wsf6z5R4t6fkI9SsHUxxko9x9i3UIIbrJz0T0LIC3dMVe2ySFCP3QByn3IEyDsuqkqKjSHMgBybimHXU3DZB+4fNxD/n1tvZWJZESAo3LsstSIRsa9rlHi4xqYt3OhCGUz10p1vGasuxqWbCjEHjsw2WhFdxDE5bgly/PRmVNWsnrvzR1fU3RMrWBVI66DPsCJiql8ggG8lPBg+56H4f+Lvvgp3Sce/B2wx/8GEPu+TDr/X9XkaGlbLkzYYisWIey/NL8xQqPfNB3VtZg3JxvQv1mwgLLs/TKjLVYeOcpaFQad9ZJfWSaqFRXuVKkW0YXISglbzKPN95PCe/MceKXHHjO5HNfsWl34HrGjbTcOcEbE4YGNc3k5lfnZP0bJyWw9sLoipTIHAoZhn9OWYXfvhG+6qBU1LrlXmMwz00ZHX/z+lz01EIix0xcjj++tcB4vKgHPpM+YwaFws591Vi0vnCSv4VG+tzrVwqmSCh65Z6vFaOGPgJpP3G1pkgrSuI5u2Vuf2M+/jHFNDXAjDy0frSd+2rwyoy1RpdRSjHz/zV1tWd84O63F2HsZyuxfa93UFa/BvlS4/jcI91tXmzaWYm9dk6gG1+chVMe+RQLvi4uBe9MWGPLnQlB0Sv3fEMRzxszFf+b/bVnebXm327btCxnyz1bpOWuN1z/nbkOv3x5Nqas2OIsI6fQhnc/Jnm/2uJW5JOXbcaKCJX7pGWbcdU/ZwAoLMt94F3v49JnPgcAfGHPByi2Qi7ZXs8Vm3Zh/Lxwrkqm4fGdV+4AMOOrbz1Wsu5zb9W4NKcydLlYWekBVfP6nfu8vnDTddhl2K5Ka7S+2urNJZOPZajmy6/NUMhkSuCDhRtCybrbHjvQJ3kVUv63MGQbGTX8wU9w9b++zOuYPX/zDkbn4O5k6p/iV+4RdFHVdLlSH+lWb1Lklp/mlRlrc5bL7yU2umUMyxat3+lZJs/106Wb8J/pa9CoJO7ZJp8GUxWjNi33MRNX4PLnpjuD40HIGcuN7YFzKWKxuTfSbpm6O2ZVTQovfrGm7g7IREbxK/cIzK9KJe49JQTueWcRjr3XnUArmUrl5JaZn4df1+8lVpcHlci74KmpWLV5tyvdggz/vPjpz3HzK3NckUKS6qTAQxMWh5bzqYkrMPyBjy3ZlOWmOPctuyo9g5m53MO131o9jo07MudZkcq9XbNyS0bH7ZX1YeuVKGYjM98dWLnDsmblC5MSwJOfLPdss3FHZU4FMdo2LQMAlMSzt2L9XmLTKftdh7Xf7sUOZRC1stp9Dia5qpIp/OXDZa5lSzfsxLg53xjz4t/19kKj397kljnp4Yk45ZFPXctyqSIlJ3j53f5/Tv0KyzZaPRfplpGTsZxZzUWmJYmjZZgsKHrlns0LeuOIHsbl+6qTTi3WR95fYtxm485K3JOhbNw/p6zyLMvkp1+zdY9nkFPi65ZRXu+0H9a8/+pUyjUjd1+NW5Ga5DP1UE56eCKuff5LfP/xSY7VbJQtg1tmqyGvfi7KPUb+Md9CCNz++jyc/tfPAChjGHCPZYR5dmat2Yauo8dhVcQRRbnAce5MNkRSrIOILiKiOfbfZCI6vPZEdpPNIGe5wb8MuH3uny7NvTTc7W/Mxx4tuVcygwvguPs+wrD7Pzau83uJTfvy27a6JuWy6nXL3TRZS1fuqm96yYZdHpeVH+Pnr8ekZZuxYtMu3DVugStc86UvVjufc0kHEdSoyfPdZ59rGPeWifHzvsE97ywEAHy8uE4zWRtx2sosdXuq2PxPTCRknKEqhFgMoB/gFORYB2+xjpUAhgkhviWiU2ElBxscsaxGsrFiShPmtiyf4tI6yzfuRp9OzZ3vSTtoPZkSOPbeD/H+L4Y5jYx6XCGEx0c9dYU5ha97IND6zec+6X5rlIRqgLfWqsnNokfUjJsbPpxOaJrnorHT0GO/Jli6cRcuGJTOBHrLq3Odz/uqs3d3xRz/s/f+6wPfustKypjp2VEjTQpBP8ayjJaRJIVALIp6jExREUmxDiHEZCHEt/bXqQA6RSFcGLLxuSdiZPQxVydTgVacnsAriCUb3BEqqmW89tu9WKOEHs5Wim90u/Vtj4X16//OhQkp677qJDbbycTuf9c8AFqdTLkiiio1t8zNr1hhbge2bews+1bLPnnd8zON+/bKZb6ISzfuAuCvIHMZNwlSdNU17mXpGb9w/c/msLWt24UQWLrBG92kEguY0xBEruNSbPEXN5EU69C4HED25YByJJti1bEYoTRuOOUMIXvxLEL6pCKTJD1pDKx91SRTePqzla51m3d7sz6akArtiY+9A786NUnhcl3pbhlJRWm6E3fWY5NCyeGVK9MWfm6mXJS7v6KrcnLb2PtXNvrf7K+d3ot63FWbdwcWefFruH40dhremuOdBJct785fj5Menoh3AnpJ6QHV7K7Xl6u/xV8/WJq1TAVVCJ7JmtDKXSnW8XLANifAUu63+Ky/koimE9H0TZs2ZSurkWwUQ4yA3VVeF8y6b/d4XBEq2VjuSzfsxJerv3UsZP0Fkbv664fLPDHa32wLVz5N7tI0mUmnJpVyXaPKmpQxAZop3j1b7h2/CK99uc53vZ+ykPLtqqzBtj3pAdfqZAoPTlhsdB1RwICqHDOQ903tufzfy7Odz6rCPv4Bd4bKsDHwny3bHLpnE4TM1f/2vPUBW2UOhZy7djuWb3IbGBc+NQ0PvmcOFAiiNgrRMHVHNpZ7ULEOEFFfAGMBnCmE2GLaRggxRggxQAgxoG3bttlLayDoAdQNbj8LfPOuKo/FrZLIQrl/vmorvv/4ZPzBTtKlKx+plJZu9HbBv85QHlCSrlGaeduqpHAp1cqaJPYYxhhM8e7ZolatMjFpmfGxcJTV8fd/hH53vucsf33mOvz1w2V40BBzb7LKJbKhdqx7ZRtVaQfpLv25MuUV0huAOWu35Zw5tFkjqzKYX+TUll2VeOFzaxA6SOV+79HPXPWCVbKdtGVKVMcUD9kod99iHUTUBVau94uFENmbCHmQTAkM6trKuE7XfTEiXDg4+/J+sSyUu7Sml2ywGgvdWk2mBPZU1RgjdzYbwgSN2LsMI1ZNMuVSbpbl7n3Jo7DcM/EHn6yUsrHarNWIldduT6W3MQpyy3gsd5dy9x5X5Zcvz8boV+d4lPneqhqs2brHFcqpHnvx+p0449FJeGBCbo+/lNlP/6qpE3L1hWdribPlHp6tu6ucUp2FQlTFOn4LK9/743a45PTIJfUhmRK+UTB6nDUR0L9zi1D77a4MMOaSI0UqS93n/vRnK9D7t+9i6nKvFRvW6ksXw8gsWFVNym25V/u4ZSKw3HPFT4dI5Wxy57wxe539W/9oGdlTk7cgJdz7Mh33lRlr8eIXazwRN3uqkjjuvo8w9L50GKiq/OTA9tx1ub3gQW5B/Vi5Kt1sfejscw/POU9MznmsqrYIpdyFEHuEEK2FENuVZU/Kgh1CiCuEEC2FEP3svwG1JbBOMiV8feK6xR2PEZqELBlXWZ3CnDtGYtwNx/qm+n3m0oG+v5fKXX9BXvjcytPx9Xavfz1szH46pW5m5b6vWrfck8aX1m8OgAn1skZRwMRv3CTu41dftH4H1mzda6/z/k7eL3n/patDFh6XBLkp9Fh/6cpS/f/ZjPfM+GorFhty/egy+5FyuZPqRrmz5R6eqNNmR0HRz1BNCn/lbnLLlIe0ULfvrUaz8hIc2qE5RvXZ37P+yqHd0aFFI9/fj5+/3gpDzMJvqeeQ9yNdozTztvs0ZZ6PW6ZzK+t8+3RK934G3vV+ZiEyoCvZILcK4LZyTS4K+fvte6vx5CfLfXPpBylJXbnvMwzEZ6Msz3liCk5+ZGLG4/ndU91yzyXpWbYNcV2luGZqh+JX7il/94TJLVOeCKfc1ZfprrP7YMZvTsSCO0/G/53U01luiqpUeemLNcgmS3BNUoR6oVbZlmgYd1F1jR7nnjIOlJWVZH4UfjKkG47v1dalWPSY+FzQdaT0sfspd7UxVxvElK30VOX/l4AQQKcoSohYebXkoNynny9fxxTt4zlehvuuHutP7yzCCXaitmzI1nL/aot/mgnJBWOm4vJnv3AtW7N1D16eHn0mya6jx+FXSrQTE0wDUO4p32gW3aKPxyiUEgPcVl1JPIbWTcpQUZpAieLfz+QW2biz0lgIxI8tuyrR47bMUwSembQK01ZscXKNBFGdTDl+/7JEDJU1Sew2DFCWZGqpYCnhOBEWr9+JvVVJJyFXvggB12DUbjuFg7x/4+Z+4wqRVGVVlXD3X7+Nsx6b5PKXByk0eY9NCeF0n7s6kPrQe0vwwcINrl6DbGS27KpC19HjXMptxSb/SCzn9/Y98rujei9j1ZY9xqpaQWRbj+CisdMybjNlxRZ8sGgj/vrBUjxgT6S74rnp+NUrc2qlGMrLeaTQrgsKKY10A1DuAW4ZbXGMKLTlnukWETJPbgqyGiV/OPNQ5/PCb/x9suoAL2BVkApjuVclhWO5Ny5LoLI6he89+plnu9IQWSsP2q8JqlMClTUpXP/CzNChm5l4YMJinPvEZOe7bDTU+6pakep56xbv7LXbXVW0gl42daavjt672bLLPcHs8uemu3pEsrcgc+j/d2Y63n+vwaWjE2S5b9y5Dw8Z4tT1sMk73pzvfP7IkAsnHzfL9j3V+MVLs/DufHMc/oPvLcGjH1mZRGWuoA07wk3Ka0gU0jBF0Sv3lPCfZKS7ZWJEOGi/JhjWM3OMfZhws2wmN/nRvW0T53PQDMkurSo8y/x6Dk3L04PGlt/fOpdGJXFPVkhJIoPlfsspB2NYz7bOdZmyfHNOKZBV7j67DwArL45qYZ/08ET87ZPlrvunXmtVR1XWJPH5yq244rm0a0AdnAwaFAyy3HW3zJZd3jDV65XJS7oV3bpJmfO5xuW+McsjFW9VUuBfU79y+ccve+YLo6LcozUaz05e5fqNTj4DpK9+uRavzVyHO/9nDmeVdB09DqvtFBvrDUEDDZ1CythZ9Mq9JpXKwnK3koc995NBWHXPaYH79a+CpOwvAuWuyh6k3E1uE7+xBnWpGgrZuCyOeevMxUMyTdTqsV8T13ciyjtUrmsbb4MleerTFb4+bXX53uoUrv7XDLy/MG2pViXV4iv+x08JK/Rx8N0feNbpbpmdBheUWstW5uiRfLRoI2Z8ZcWmq9fJL6pCNkgLv9mB37w+Dy8o1Y/8Cr5km02zJpXCdc9/iVP//GnmjX2OlY31/8323Ht2f3hrAcZMzJxeo9AopAijolfuqSwGVPXv3du4XR2u/frco/5drEiRwd1bZZVzxo+ws1+NOXF8UC16NWLH5Gt39u8zV0ASt902Mq8JAVlFApkI8vMnU8LVwFYlk3hu8iqc8shE1/K9VTWeKJAwaRkAqwF/ZtJK47p8I0V2VdbgnCemAHBHqQz3mT3qCb2srMGzk1Z6Er2phHH3qNSkBN6a840nJDQMUmllo7vyGZN5+rOVuPvt4PoJhUgBGe7Fr9yTKeGrIA/t0Mz1Xbfw377xOHQMCGc0cVT31pj925EYfnA7xCK4emFdO6Zslg/7FBZRY/mrkyn8/CUrwmBHwABXIsPJODHnig7KpWC4StAkrKSeqrg6hd+9OR+L1u90K/fqpMdaemduUH6WNEIIpzqTTpRhgJli2E3He3/hBtzxvwX46wfLfH6Rg3IPkOPoP33gpDcwkS7aHv6e5/l4uCikgcogoqjpHBVRFesgIvoLES2zC3YcUXsiu6lJCV/3yC9H9sKr1xyjyOleX14SDz2pSaV5hZUHJBrLPVwLccLB+zmf2yj+XBPtmqXXq+4KP2VwWp/2ngFbnXRZO/vhpfy7oEHtmm65q35x9bh7qpKeF2pbyCiSlEgXzQaAw5XZy7nkmPcjzHXSlXuZPfC/eqt/OKIpR1A2x5AkUwLfbN+HW1+zUky/MmMtnp/mVvTyXmTjiosyZbBpV2/N+Rrz1m33rqhHisrnLoRYLGeeAjgSwB54i3WcCqCH/XclgCeiFtSPlBC+8ebxGOHIA1q6vutkmz5V37/KT4Z0w5iLj8xrHyZm/24kzuzX0fl+mmFSlYosBK1jejFH9dkfj17YH0d1b423bzjOt9ZrujiG9Z189qfz+a9HhE4PocvqLjKSVmQun3tVErp3KKy7KKVZ7h2ap69bVGGeQLgEXLp136yRJVdQb8s0sSqIN2aZw3J1pf/Ll2d7agnIe53NRKgoFJ2UzbSv656f6ZRSrAuEELjzfwsw/2v/BkUU0LyvSIp1ADgTwD+ExVQALYiofSQSZsByy4Q7DZMyyef503sM5SUxjDw0WPHqJEKEIDa3MwamfxN8vscc2Nq43OS3b1yacHz0vTs0Q/vmZjeVx3JHOIt0v2blWPLHU/H8T72FubJyyyiWuzpJaf2OfZ7Bz7DWpWW5W0o0HiPs1zTd49ldFZ1y1xW3EALLN+3CvHXbndqsuoKVLpSgWHY9WiYTajTNpGXpcpKZZscCaStcvbaZ6glE4aKQ8wvC9hJXb9kTaWU1lR17a/D3SStx/pipvtsUlVtGw69YR0cA6pS0tfYyF7WRzz2ZEsaZqIBXcZse3nxuhX7cICv82cvMeWhyCacMen7evG4IfnTUAcZ1L1w52BVXbzr+/s3NVr9sF+Shs42WKTNY70HKJCk0t4ziJlEV/TbDDNmwYwGqz33/ZuWu1BRRWu56T6ImJTDiwU9w+l8/w/H2TFPPgKqtuHcEKfdqS8bx877BUxnSLetcNHaaM09BXq8gN2PSoNzvHR884Hnf+MWuymO5sGmnFQIaRmfWJFMYev9HkeTXN2JfnqDxmKJyy0gyFOswPRWes6ytfO66QSoHWHWXSxQ+8qD9BSnqg7RQQkk2ueIlQQ9Q304tfOPfD9qvKS4+uqtLqerbdmrpZ7lbF9md48T7kMcIOMXQeymNeyePBVnuQnjj2dOfw0/VDyIlhOOGeuGnR6FMeZB2BUQWZUPX0eOc9M8SUwFy3ccvUxYEnascQ7n6X1/irrcXZi2bDLGU8gT2pOxnLtu8Nm/M8i/eEoZN9uSxoGf+/ncXYdSfP3Wu1QeLjCUnMrJjXzWWGeosSCrtHkGQ8VBIpQmjKtaxFkBn5XsnAPnXHguBlTjMfRq6f9hZbvK559HS6t6gIEXt5zrKzXLPTWZ5LPfkIPc2vdunI4weuzA9Lh53rqkdCknmKJCUAJ40jDuY3E+ZvGmq31dVcn7hi5KwRSZkCuAmZQl0aV3hcneplnvrxqWh9ueHLMN3/fCDAHhdLcmUwIYd7gk/e2y3UJA9smTDzryUyU//MR1PTVyByXb66aBjqa6wbHps+Q5MS8s9SLk/9tFyLPhmhzNPJNPrseDrHXaj61bkD01YghMfmogrnvsCEwwzcQfZ8yGCU1oEH7suiaRYB4A3AVxiR80cBWC7EMK/GGSEmCz3uGO5uzH63PM4ttdy97+cfko87HiBSq4PUMJR7ull+jU5u7/Hm2ZtF3Mfe9uealz/Qvjur2mgNkw+eomq3GXhCr8w1rAzZ1du2o2nP1vpWMlqA6TWt73pxB5Y+adRaO/jssqEPE+ZVvnoP33oWr9jX41nopKckxCUP2jqiq34cw61UVXuenshbnppFoBgQ0NNflaTFKH92rn6v2WWUpkn3zto7n0JVBn/84V/4rJxc63GVlfgny61XMXvL9yIK/85I3uhAZz08Cd4OIeShrVBVMU63gawAsAyAE8B+FnEchoRwhp0ixPhtL7p8VvdypQYn908tLv+Mpgs96uGdsfYSwYY1w3t2TYnyz1Xv55UMqorRlewrZuUOW4VdZVpQFVyXI82nmWf3XIC3vv5UOe7eYZteNkrDUri2hMOMm4bNNCoXu9xWjFqv55XWSIeKne+H/IaV/ikm/7jOO+U/t0hLHcAeGdedDZUUGOrTgyrTqVw8O3jQ+1TpruYsnwL/jlllXGbJRt2eqJwpDEgLX/9uTP5vXcpMt786hws8JnZK9Ef5SiM7p37avDnD5bigoBB17oiqmIdQghxrRDiQCFEHyFEnVRiko13PBbDYxce4Qza/fHsw3BElxY4pL17EpPp4X3iR0e64sKzQX/hTW6fa44/ECf2bmdc98ylA3P0uWf9EwDhLHcVdU3cx9UFwBWmKenUsgI92jVNH9ug3LNRmKbC5qZ8O0BwVSN1VrJu/fn1omQm0XzHyvyUu8xb8+xlA/H2DceheaMSJ+1xprS7uj8/H0y3Q84DUTM86tXFgpDK+YKnpuL2N+Z71q/esgcjH57oGZyV19ovFPL21+d59qXPTN6xrxrPT1vtMfJkb0g/C30QPcj9+WEGv76amgIIXx85Sop6hqp8OaXekFZZv84t8NrPhniqC5ms5F77N8VDP+wXiTymqEZpsZqUeDxGzrR+P3opClKSq889ZvC5m9oWU+x/LMByD9M+6W4ZInPDcuupB3uWNS1LGKNXMqVMMKE2Mvq5+IWlyhDSXOdEyDbDr9pVRak1me74Xvuhd4dmKEvEPOGdOof7lIvM1XUEmO9Hs3Kp3N2We1gyuWU277bcLp+v+ta1XA7gSoteDzE0pf7VxzLufnshfv3fua76s4B/NJ1eqzdoZvFPng1vv05evhnH3PMhHvtoGbqOHofPlm7O/KMIKGrl7tQStbWLacBQxc9QjKpWZFyzTq8a1t2x1vx97gGWM1kpEnSyccuYonRcyt04yJw+vi6n6dBhfOclmlUcJzI2ClcNOxC/OrmXa1mzRiWewS/AHF6ZUQ5FgevX0e8eScs9VyNACKsBLPNJN72rssbVUIVptG4+uZcxKskvnUIYTOfftNyaY6Eq9wnzw0ejZBpQjfm4UOW9kQoDZs5pAAAgAElEQVQ2zCO/ba87c6fsEak9ub1VSazYZE7eps9tUAfm85kJK91Df/vEmhfw2sy6yUlf1MpdKmWpeBy3Q8jiHZKgWOJs0BX1race4rgewhYUUSmJxYzr9bbo0Qv7e7a59JiuuGH4QWhV4Y30UK27YMXs9c2bGhZ1F22bml1cJZrCihF5jn3sQZbvXj/nddv24svV3sLTYQuv+KFfxyCfOwAMOSg9tvDB/w0L7VLbV51CIh7znf27q7LGNcFMn7RmIh4jYyNQnsc1MZ2OaabsbwwuET+CEp8t/GaHk8RMCOC5yatwtx3SKfVqlcEt41eLdrs250Ev1wgAN7440xlrEbDCOndVWsnn9OdBtdxzmQkrGywpuqOX6iiipqiVu3TLSCUho1X83jm/LISmlymX8bOgOPpEPIbfn3EoLhzcBQCccn2B0TI+u+umZbM8vW8HzzZ3nHEofjGyl+MSePJH6bDGf14+2MklY7pW5w+yolr7dmruLAsaUJXXv2VFCcbdcKxRZl0RlpXEPNf4qUusuuphOya5RRoJ42d1f6ce5raITUq0bdOyUHVnAWswuCRGvvH3uzXLXU2Z4Uc8Rh430oFtG6N149zGjwDzGIjJcs8GPXJp9pptTvjmqX/+1MlnkxICv3tzPsbYk7GkG0YWXlEvnV+CM90to8+8/XTpJkxYkO51CAE8/vFyHPa7d53SlSr5Fn/vduvbqE6mHHeenHBXVxOdilq5p3wsdz/UIhYqQ3u2xb+vsKbHNylL4M/n98N7Px+WtTyZIl9+fExX3H12H6y65zRcP6IHgOwiRiRXDzsw9LZS8ard9f2bl+MsexDUZLkPP7gdVt1zmqsAeDzALaOOdezX1Ozz1RvWRiVxz7GztTqDrveVQ7sbl6sNgn4uUlnq+zW5fxIx8vRG/NhZWYPdVUlfH+6ufW7l3mt/7ziLTjxGnnQSr15zTF6KY9POSk+++WY+74yJp388wDsJTrhdLmc+Ngl/N8xTUJX3pGWbFbeMrdyVDb7d4y2cAnhnK0t3jDS6nvzEnS5BABg3x7LiTTnzo3DXWufiXlZXofBFrdzlwI70dfsVVJY0K/fv7g45qA0e+uHheOv6Y3Fmv46+M0qDCJMnRicoYkRf88rVR+PVa45BPEahuu6A/zXp2c46Pz2iyI8gt4yc5NM1ID++rjArSuMey11ei7ADl0E9pbY+mTM7tmyE+87pa1wn7/ngbq1cy02WeyLm72bxQy0ioqK7ZUyuNJ04uS33HxzZCS0qSn1nT/5yZE/jch298HbTgHdGp1ubxhjVx51SSkB4rHdTBJDaAFw0dpoSLWN9UJ+7jT7l+7yWuwy4sK7TUkNkkXTtmfYZRdrnS5/5wlNHua4mOhW1cpcts5w2Lh92vwc80wDc94/oFKigMpHNpJxcGNC1ldNlD6tY/GbrnnJYe7x701DX/IAgZK+osyH8cGDXVvj7pQMw2hDp4kej0kTo69WiwqxggrwyflZ9KiXww4Gdjb2EQzs0x6TRwz25eUwDoYkYhSoqrlJRaraCd1clXQ1IyxAzYuMxcvVC5KX0S1zlNycgE369XRNlJd4GOyW8Va3M40hmudM+9/SyTbvCKXf9txt3en8ndcL6Hd6SgJlyFM1Zuw2L1mcufKI3ZnWVm75BKHf5YvzmtN5o1bjUN/lVPhNRwhBFTdWojxXUmwnT/ZfIwaBHL/Cm6o/FCMMPbucbDWLCZLlL9Gd/nB377TluwP30a/z0cRqdji0aeZ4Tk1EQy0G5j+zdDt8/wjsnIJkSbuUexnKPkev6OZN9Um5rVUJEnqRxAPCb0w4JPE55STx0FbCyRMzTm0oJ4SpYDlhKV/ra09uZ92mKc9cLg0v8Mmj6pqMQwglP1dM/BP7O5oxHJ+GURzKXLNRf1brKLRZ2hmoLInqFiBYR0UIiOlpb35yI/kdEs4loPhFdVjviupEts3wxTurdDl/efpJvPHFtE7VyD2qLgqalq4w4xCrykU+PBEifW3MfKzpbKkq9PneJnsulY4tGGKEUK9FlMqGmgnjyR0c4g6RO+GwWDb1faGI2bpljDmwNIsIFg7oY15e5LPdw0TIqssaptNxNLqtOLb29rjP6eQfj9eNUlIV7n8oS3uguk+VeVZPyDIou22iejGXyufuNXfgp92RK+GanlA3XZkNvIEwFLQDG/O7qoLh3JmzdaPewfa4/AxgvhDjXzg6pPyXXAlgghPgeEbUFsJiI/i2EMI98RIRjuWdpQdUWYf3gUaA/IE3LExjYtZVnuwsHdcFpfdqjRQhrMIioM2qWawOq429Kx/P/YEBnJOIx/PLl2c4yk3sgTBZDwHJBxWMxvDNvvWMhZnM6fu68bCx3qdT9GqSsfe7afuRkIadnEgOQDP4NgIwRP/EYoXFpwphaWacs4W2whRCornE/q0EziHXSPvfM2+7ySdM8ZfkWXPz0557lApYrCUjnjXcfO5ycD7y72LOspWIE6WMOeZYeDk2YMnvNAAwF8DQACCGqhBB60LEA0JSs/mwTAFsBRJcQ2wd50TLFOz96YX88fN7htSrLI+f18wzEheV33+uNAw1l7oKsc/1hn3vHyfj7pd6c8USUt2IH3P7tT28+Ie/9nd2/o6u7evD+6YHdeIxw7pGdXNubJucEWe56laKE5p7KZLmrL6ef5Z6p3OHJh7bz7MOvkVSPkakYi2k/UrnLNs10HNP1yuRKS8TImYiXqWNaEvfOXUgJ4RlI3pNFIRS/9ANXHNst9D4e9ykqIgRQbl93OeFJPUfZsGTyq5sMfPWd03sudWW5hzE9ugPYBOAZIppJRGOJSNdEjwI4BFaa37kAbhTCW3Aq6mIdYS330/t2wNn9OwVuky9n9e+Ys0//siHdMMjQMATtrq5rAqjKwjSomg3L7x6FUX3aZ3W9TOXmgnoTe6uT+Py2EfjithMBeNMnZFJUU389wokk8nu+Hj4veMbqH846zPnsKHc/y11rQM45Ivh59XPL/OWC/vjRUV3Qu4M3Csp07EyupRgRKuyGNVNDQESeDK2pFFClWe5+FraJ6mQKv/jPLHz/8cmu5RWlcezvU04yLALCCWfdaodXqj0ZGeeeKQmYnna5bdMynHG4v7urkKJlEgCOAPCEEKI/gN0ARmvbnAxgFoAOAPoBeNS2+F1EXaxDH1AtFD6/bQQ+uyVb6za7hqGuRtxlvHiU4wnpNBHhfyPzev/lgvRsXDLc9nQ2wST2a1ruzJiVxzJZ7ved6w2NLEvE8eJPj8Kb1w3xbYRaZYhqUaNZSuNe5X7VsO443Y5W0huQB394OI7q7t8T9Ch3u6fSrU1j/PGsPsaeiWkeiOncrhza3clplIiTU0Q8qIcsxzT02eE1qZTHcs1Guc9btwOvfbnOabwkiXgsEgtYKmYhrGdH7TVNXWHlpMnkRtJTY9w26hB0be0/xlVI0TJrAawVQkyzv78CS9mrXAbgNTs75DIAKwGEj4vLkcoCVe77NS03Dl6F4Q9nHYbJo4cDCFb3dWW4/3rUIVh1z2m+Cm6sPas0FzK5RtSapr8c2QtHdW+FE3qljQKT5V5uW5e6MpDbSstdns/I3u3wwwGdYaJ5RQn6djIn6DKh6041Dl0+o6qCjVN6IpLpGZYWXvNGJXjioiPw7k3pFMq6cldTIwDmXl/YBrpD83KUJGQDTI5LLKiH/H27p6Hfk5qk8Piud+U421UlHqNILGB10LQsEXddo4fft/KyZ+ph6iGW8RgFNoQFY7kLIdYDWENEMpvTCAB6AurV9nIQUTsAvWDld69VZN6KXBJIFRry+SGEewnrqvXPRDZx0Ccesp+TfgHIrNzf+/kwx7/fo11TvHjl0a5JNabrNNB2bw050K3sHLdMSh7b+p/J+s6Gnw7t7qTIBdyKXCpG1bKNKRORjAaKfYsfvbA/Tu3T3hW6qp77ZUO64vbTe2eUL2yEkBpDn4iRM5ZkihOXyD3rx6hKpjyWbxQlDEvilPU7oM+2FcI9aFqaiBmvUbZ91kSM0LKi1LeYTCFZ7gBwPYB/E9EcWG6Xu7ViHX8AcAwRzQXwAYBbhBC1ntfSmcSURXx11Jw/0Gz15YpAuIepUMp5ZTMrd+yPB+Lus/s43zPpmuYVJYH+fdOLeFiHZlh45yk4sXc747bScpeKKtsp5uNuOBZP/9jcW+nTsTnm/f5k57uqgE2Wuxorb7bcZXoN7zrVQu7YopEncsekP8IOccRjMefYZSWxUL0XuW+PWyYpPG6ZsMXHWwaE3SZisazGnW4Y0QNvXe/OsCrgjmW3QjnD79MPmdRt0ujhxpTddfXuhjK7hBCzAOhP9JPK+q8BjIxQrlDoce71wT3n9MU9PtPZs8FJGCeE0w0M6g4WiuUeVFowE/nO6DVZ7gJAI0NRDPnS6jM4j+iSOUmXyqEdmuPQDs2N6/TzUdMcy2fUVb+W0sq9zKBVHOVuaEAz1QGQPHJePxx9YGsA4edGJGLkhD62a1oeqnfmJO/TDlGTSnkmMekuMz9G9t4fL003l8tLxCkr1+RxPdqgdRN3Ly2VEppbJmb2r2f5mKr3K5vZuFFT1P6MQotzzwf1xVNdNH4UiG7PqZKUJN8xWmOhEZ/r0q2NlTfmosHu1AIXDIqu56Ur95jBLeN+8dPbBvncTY1gnChQWcvJSYO6tUI7O6pE343fexOLEbbZ0SPtmpuVuyehmL1vXZlVGyx35ycZ7n9QIrmE0rsIQ4cWjTyNZE3KPR6wasseY7rwIDFNVdxUg8ek3PcGlIGMkqLWioUaLZMPVmGHzNq9QHR7XlE0+Vrupp6NXwRFq8alWHXPaZ74+XxTUrx53RDnc9ClKDPEucdiab+xybUoAsI2M133Cwd1weI/nuLK7Kmz5K5TjcsTMcIOe9CzXbNyNDNMztMTiklp9DQX2/dW47rnzYXUTS4LlxwBRlsiRp4QxCDaNS3zFIzZV530DO7q13XLrkrnWgDu2dMlcTLOv1ANHmOt1yyihfKhqLViQ1Luqo4Joy/li68ql7pEhhzmY7nnqlf/dvGRGG5IRwDUfY+mb6cWONFO8WBqrOQAq1QaqvKIUzriI2vLPcN1J6Kcx6LiMcJdZx+G9s3L0aQsgSaGhGeN7ZQE8jmQjWTYKfuA2X2mEjSeY3LLBOmBRDzmscr/PW01pn/lLu8nG99OLRuhVeNSDLjrfdf6U/ukc/2XJ8x5d9R7Y3oe9YpPtUVRa0W9ElMxc4ztFz2sY7NQvlH54jfJo6xaPsj8PflY7rlazScfur8zG/fz20bg1WuOyXofE34+FFNvHZHT8XWuOM6aC9C/i3fg8ZVrjsalx3R1onJcyj1GTk/DWO5QrvNxy0hlFjYNgrqbv1/qH8IajxEuGnwAptjXxySbvP/NG1nnJXsm2dRX1VMf6Ioy6L1OxGOe7muu78KxShipPNeyRMwqtKEdo1PLClw2pCsAa9a0qUFRJ4aZepJRhIKGoX40Q0SkhABR7Wd7rAtOOaw9Zv32JLSoKHXKhQXHuZuz/9UVFaVx7NxXU2/Hl+jFQa4+Plwhk54ZXALZcFT31lh1z2nGdQfv3wx3nJHOxqher5hiuZsuo9STpsc7FiNcN/wgpITAeSEjtuSxD+/cAsMPTkcTPX/FYFw4dppnuyCk4r377MOweuseJ1wy6WO5J2LkiUwyFrBPqr/J4JbRNG+LRiXGHDGZEBAojcdwQOsKpyEtL4n75paR2xzfqy2WGhKeZQoy2B1BKGgYit5yjzqhVX0i81GEmXnn5BCpN+Vu2QVRFRePgjZNygILshQCHstdJjIzNOVDe1oTtvzq0jYpS+DXow4JnQW1V7umuH74QXhMq7l7zEFtcHb/dCpi0zv1+rVDMPFXJ3iWt2xciiuO6552yxieh2cuHYiH7FQNjRVXjG65689yoOWuTWIqTcTw9KUDc7Led+6rwbzfn4x3bjzOsdwt5e49FyHSaQkOaN3Y6JZJBLhlDt6/KaqSqcDaslFR1Mo9lRL1bjnWBs4LHxQKaf/PpY5oFBxu11fVB6nqhcJpXzListyVAVXTY/yrk3th8ujhTrQLACddQS4QEf5vZC/j7OkHfpBOrGcKs+zXuQW6tE7/Tl5y3WWkW7u/OKknju/V1jlPdXBWz2ujX4Mgu61EST/w7k1DMWX0cHRr0zhjfnoTzcpLUJqIIRFPx7mXl8SMNRAE0tE/jUpixlKLQW4ymUOqLqz3SPK529scT0Sz7Hzun0QvqpdkA1Xu8qFuHDTgVM+W+z3n9MXzVwx2vfD1RYuKUpQmYrjttFrPeJE3qlUcJ8Vy94mI0aNdHjmvH+YrE6WiQn2Mwoxh+aVOlgqxSVkCPziyE24Y0QNEaRfKoG6t0MMuZ6hXnNKf5aCMu/EY4bZRliI/aL8maJ0hQ6eJMRcfCQCuAiry/gQNRsu0J41K4yg1NIRqPL1sHn5z2iG45/t9nAlhO3xyz0dJJPnciagFgMcBnCKEWE1E5lCGCFixaRc+XrwJZ/fviKRoWG4ZSYuKUtxyysFOMiYT6dmL9XP+5SVxHKPlM6kvShMxLPmjOayv0HC7Zby5bjKRiMdCpQTOFtIanUzISVf6ttJyv+nEHs5AM5BW1HEiTPj5UGzfW41Xv1zn+q1HuQeEPiXihIuP7oqLj+7qWp6pE/fqNUfjnCemAABGHro/Pr35BNcsaHVAVaVxaRy7q5IQIh2lV14SdwZUS+Mxx6I3VdJq27QMZ/briMnLrIn7X2/bm3cBnUxElc/9QliJw1bb22yMWlDJgm924M63FmDTrkqkUsI4kt8QuOb4AwNvvnyIw85UZAoDVYnGKB3OV0h3MUxv8OHz++HqYQeiT0f3bF1Zd1R3TaiNmKwxoBsm+nGDZmFnW+JQcuQB7kybenoL2VipeqVV41JXIyIbsNJ4OhfNz05ID+S7QyHdgQ/SJbZ2296c5M+GqPK59wTQkog+JqIZRHRJ5JLayIEnIayWvSG6ZcIg6tlyZ/JHHVCt7eLq2RDmnerYohFGn3qwx7iSxcw9Rb4NUUH6b/XxI9MMVCcBm8/1yneeg5RJ7ZH06djc5X6qVhowebxMg9ryPd2/eTliBKz9tvaVexi3jMznfr0QYhoR/RlWPvfbtW2OhJUZshGAKUQ0VQixRN0REV0J4EoA6NLFXEsyE/IiCwgkU4X1UtQlqXr2uTP+XHpMV3wdwjKLxwjnD+qMV79ci6PseQ6FQD7P1HXDD0LHFo1weh/3wG/SGThO7zvIMOnXuQWuHHogHvvIXUWpeUUJNu2sDD2F/5Hz+uGwju7SEq0al/qGTDqWuyKaXihbumVKEulB10Ylcdx7Th+nULnE6WHH0gnibjqxZ9Y5jXIhjHI35XPXi3WsBbBZCLEbwG4imgjgcAAu5S6EGANgDAAMGDAgpzZWXnMhZLRMLntpONRXtExUXDW0O47qXjiKLQrUuPYgYkQY2LWVb4x8fZHPM1WWiON8QxFwpwKWsmvdX6+6YR784eHGmsQHtKrApp2VoSdLnaWEeEom3nyCJ5mZI1PM65ap0UIi1ZxW8nxiMcJ5Aw0Gq/1TtSG7YUSPULLnS1T53N8AcBwRJYioAsBgAAsjldRGfR4a6oBqGGTCq2I33G8ddQhO8Ekl0NAp1DoEtWEvSB+56r7Qewgyrh9IK8P7z+2LHyj5gO4441DcNuoQDOthruQWZo5Ik7KE121kY3LL1KSEa0xEzUY7zJZZr9mrUx897LDRMjKfeymsIhyXyVzuQognhRALiWg8gDkAUgDGCiHm1YrENtJyb6gDqpm466w++O3phzaI2bnfVcpCTj6qa2qjN3hWv45YtXk3fnbCQc4yXeEN7t4KExZswNbdVY775gcDOqNN0zK8PGMtACvq5KdDu8OPg5WCJoGhxD706dgME5dsQve2TZxl6kQ9IdKZJMsSMfzgyM4oS8Qx8tB2nn0B6nyUAlXumfK529vcD+D+iOQKwB5QhfhOD6jGYpQx8RJT2BRqquqgd+qpSwZ48qKHoTQRw82nuOch6MdJKWNortTIigFjysKocuQBrTDl1uGYvGwLjjwge7/2z0/siRGHtEPPdk1x7/hFAIDT+7THtr1pH/3lx3bDL/4zG11aVyAWI6PrR6eQLfeCwRlQFfYkJrZcmSIlqM5mfRKkiE7qbbZQc6FCM07U6Ji4z8BrRYjeTvvmjXCOlto5LIl4zBnsvO+cvjigdQUGdWuFByYsBmDpne8f0cmpGZsJJ6qtHkKWi0+5K59T4rvrlmGKn0L1udeVC0FPg2DpQSfZjoOesqGu+GGEJTTzqViWK4X5dAUgfcxsuTPFTn3W/g2iruojdG7lTq3gNxhaH1ZvVNSnz734lLv934lzZ8udKVIK1XKvq7GACq0IiF+C0fqwenXC1p/Vqc/srfV/1bJE9bmnBMe5M8VLofrc67Ky2co/jcJVdvRLWSKG20/vjaZlCbRolB60LaTeebaTc2RvpGCjZQqJ9AxVdsswxU2humVyzduSC0SEm07siVaNS3Fmv46Ixwhn9nNHnxRCRNzhna1sjnounbBwtEwI0rllBA+oMkVNobpl9DzrtU2j0jiuGuZfQUuGXl41zD++vbY5qXc7TB49PLDguIn6dMsUnXIHW+5MA6FQlXuhTYxr16wcC+482eOjr2uyVewA6jUxXGTFOuztBhJRkojOjVZM5RjK55rv8AxVpvgpNCVayNS3Yi9GwpoOsljHwbASgnnyxhBRHMC9AN6NTjx/ZPoBTnnLFBu51PlkmGzJ+JQpxTouBaxiHQBM+TKvB/AqgIERymeSx/703U4/wBQvE34+FF9t2VPfYjB1gEwRUh8ehjAmhFqs43AAMwDcaKf3BQAQUUcAZwMYjtpW7vZ/J3EYd22ZIqNDi0Y5+W+Z4uPvPx6I12etQ4fm5Zk3jpgwbhlZrOMJIUR/ALvhzef+CIBbhBCBeS+J6Eoimk5E0zdt2pSTwK5QSLbcGYYpYLq0rnCKhNc1YZS7qVjHEdo2AwC8SESrAJwL4HEiOkvfkRBijBBigBBiQNu25nzMmXCV2fsOV2JiGIYJIqNbRgixnojWEFEvIcRiGIp1CCG6yc9E9CyAt4QQr0ctrLV/55hciYlhGMaHSIp11JZwJtLDqeyWYRiG8SOyYh3KtpfmKVMwam4ZHlBlmEhhW6nhUHQBt8SVmBimVphzx0g2lhoQxafcFb8Mpx9gmOhoVl5S3yIwEVJ0w5GuSkycfoBhGMZI0Sl3iTOgypY7wzCMh6JT7u4ye1yJiWEYxkQRKnfrv4DgSkwMwzA+FJ1qVHPL8IAqwzCMmeJT7kpuGR5QZRiGMRNJsQ4iuoiI5th/k+3skbVEusweD6gyDMOYCRvnLot1nGunIKjQ1q8EMEwI8S0RnQpgDIDBEcrp4CmQzZY7wzCMh0iKdQghJitfpwLoFJ2ImjzOQS3lzm4ZhmEYL2HcMmqxjplENJaIGgdsfzmAdyKRzoATCgl2yzAMw/gRVbEOAAARnQBLud/isz7/Yh32/1TKiphhtwzDMIyXqIp1gIj6AhgL4EwhxBbTjiIp1mHr8qQQAFi5MwzDmMio3IUQ6wGsIaJe9iJPsQ4i6gLgNQAXCyGWRC6lgVSKlTvDMIwfURXr+C2A1rDK6wFAjRBCz/8eCTLlb42t3DlFKcMwjJdIinUIIa4AcEWEcvniuGUcy70ujsowDFNcFK1qZMudYRjGn6JT7mnLPQWAfe4MwzAmik+5az53Vu4MwzBeik+5az53dsswDMN4KVrlXpNky51hGMaP4lPutlvGiZZhy51hGMZD8Sl3ablLtwxb7gzDMB6KT7nb/9PRMvUnC8MwTKESVbEOIqK/ENEyu2CHJ/dM1CQt3c4DqgzDMAaiKtZxKoAe9t9gAE+glot1cJw7wzCMPxktd6VYx9OAVaxDCLFN2+xMAP8QFlMBtCCi9pFLa0kEQIlzZ8udYRjGQ1TFOjoCWKN8X2svixxPnDtb7gzDMB6iKtZh0rBCXxBlsY7qJFvuDMMwfkRVrGMtgM7K904AvtZ3FE2xDhnnzj53hmEYPyIp1gHgTQCX2FEzRwHYLoT4JlpRLaQq5zh3hmEYf6Iq1vE2gFEAlgHYA+CyWpAVgNfnnmDlzjAM4yGqYh0CwLURyuULV2JiGIbJTNHN7/RWYmLlzjAMo1N0yl1Sw2X2GIZhfCk61ajPUGW3DMMwjJeiU+4SdsswDMP4U3TKXca5765MAgAqSuP1KQ7DMExBUnzK3f6/fW81AKBZeUn9CcMwDFOgFJ9yt7W7o9wbsXJnGIbRKT7lbtvu2/dWozQeQ1mi6E6BYRim1gk1iYmIVgHYCSAJoEYIMUBb3xzAvwB0sff5gBDimWhFlcey/m/fW402TUodHzzDMAyTJmz6AQA4QQix2WfdtQAWCCG+R0RtASwmon8LIaryF9GNqsrZ384wDGMmKp+GANCULDO6CYCtAGoi2rcbRbs3LsumbWIYhvnuEFa5CwATiGgGEV1pWP8ogENgpfmdC+BGIURK3yiafO5p7Z6Is0uGYRjGRFjlPkQIcQSsWqnXEtFQbf3JAGYB6ACgH4BH7fJ8LqLJ557+zIU6GIZhzIRS7kKIr+3/GwH8F8AgbZPLALxm11BdBmAlgIOjFFSiqnPO5c4wDGMmTIHsxkTUVH4GMBLAPG2z1bCKeICI2gHoBSvve63CljvDMIyZMCOS7QD81w45TAB4XggxXivW8QcAzxLRXFjG9S0BkTV5oYY+cl4ZhmEYMxmVuxBiBYDDDcvVYh1fw7Loax12yzAMw2Sm6KZ3qp4YLrHHMAxjpviUu2K7cy53hmEYM0Wn3FW/DFdhYhiGMVN06tEV585uGYZhGCPFp9yVz+yWYRiGMVN8yp1DIRmGYTJSfMpd+czKnWEYxkzxKXfOLcMwDJORSIp12NscD+ARACUANgshhkUnpp9ctW2vuVgAAAgbSURBVH0EhmGY4iSSYh1E1ALA4wBOEUKsJqL9IpHOdCzFMZMStXUUhmGY4iYqt8yFsLJCrgac7JG1gmqtp1i7MwzDGImqWEdPAC2J6GN7m0tMO4miWIdKSrByZxiGMRHWLTNECPG17W55j4gWCSEmavs5Elba30YAphDRVCHEEnUnQogxAMYAwIABA3LSzC7LnXU7wzCMkaiKdawFMF4Isdv2y0+EIZNkFLh97qzdGYZhTERVrOMNAMcRUYKIKgAMBrAwamEtGdKfWbczDMOYiaRYhxBiIRGNBzAHQArAWCGE3gBEghr9mGS/DMMwjJFIinXY3+8HcH90oplR0w+wW4ZhGMZM8c1QVT6zcmcYhjFTfMqdo2UYhmEyUnTKXYUtd4ZhGDNFp9zdPvd6FIRhGKaAKTrlriLYcmcYhjFS1MqdQyEZhmHMFLVyZ587wzCMmVDKnYhWEdFcIppFRNMDthtIREkiOjc6Ef1JperiKAzDMMVHJPncAYCI4gDuBfBu3lKFhC13hmEYM1G6Za4H8CqAWsvlrnPZkG51dSiGYZiiIpJ87kTUEcDZAJ70/LIWOa1v+7o8HMMwTNEQVT73RwDcIoRIUkBhU7thuBIAunTpkqvMDMMwTAaiyuc+AMCLdiHtcwE8TkRnGfYzRggxQAgxoG3btnkJzjAMw/iT0XK3c7jHhBA7lXzud6rbCCG6Kds/C+AtIcTrEcvKMAzDhCSSfO61KB/DMAyTA5Hlc1eWX5q/WAzDMEw+FPUMVYZhGMYMK3eGYZgGCCt3hmGYBggrd4ZhmAYIK3eGYZgGCCt3hmGYBggrd4ZhmAZINil/C4Y/nnUY+nRsXt9iMAzDFCyhlLudM2YngCSAGiHEAG39RQBusb/uAnCNEGJ2hHK6+NFRB9TWrhmGYRoEURXrWAlgmBDiWyI6FcAYAIPzlo5hGIbJiUjcMkKIycrXqQA6RbFfhmEYJjciKdahcTmAd/ITi2EYhsmHqIp1AACI6ARYyv1Y0064WAfDMEzdEFWxDhBRXwBjAZwphNjisx8u1sEwDFMHZFTuRNSYiJrKz7CKdczTtukC4DUAFwshltSGoAzDMEx4oirW8VsArWGV1wMM4ZIMwzBM3RFJsQ4hxBUArohWNIZhGCZXSAhRPwcm2gTgqxx/3gaAX8x9ocAy5k+hywewjFFQ6PIBhSXjAUKIjIOW9abc84GIphe624dlzJ9Clw9gGaOg0OUDikNGHU4cxjAM0wBh5c4wDNMAKVblPqa+BQgBy5g/hS4fwDJGQaHLBxSHjC6K0ufOMAzDBFOsljvDMAwTQNEpdyI6hYgWE9EyIhpdj3L8nYg2EtE8ZVkrInqPiJba/1vay4mI/mLLPIeIjqgD+ToT0UdEtJCI5hPRjQUoYzkRfU5Es20Zf28v70ZE02wZXyKiUnt5mf19mb2+a23LaB83TkQzieitApVvFRHNJaJZRDTdXlYw99k+bgsieoWIFtnP5NGFIiMR9bKvnfzbQUQ3FYp8OSOEKJo/AHEAywF0B1AKYDaA3vUky1AARwCYpyy7D8Bo+/NoAPfan0fBypRJAI4CMK0O5GsP4Aj7c1MASwD0LjAZCUAT+3MJgGn2sf8D4Hx7+ZOwir8AwM8APGl/Ph/AS3V0r38B4HkAb9nfC02+VQDaaMsK5j7bx30OwBX251IALQpNRvvYcQDrARxQiPJldS71LUCWF/5oAO8q328FcGs9ytNVU+6LAbS3P7cHsNj+/DcAF5i2q0NZ3wBwUqHKCKACwJewirxsBpDQ7zmAdwEcbX9O2NtRLcvVCcAHAIYDeMt+oQtGPvtYJuVeMPcZQDNYBX2oUGVUjjUSwKRClS+bv2Jzy3QEsEb5vtZeVii0E0J8AwD2//3s5fUqt+0e6A/LMi4oGW2XxywAGwG8B6tntk0IUWOQw5HRXr8dVk6j2uQRADcDSNnfWxeYfIC53kIh3efuADYBeMZ2b40lKwlhIckoOR/AC/bnQpQvNMWm3MmwrBjCfepNbiJqAuBVADcJIXYEbWpYVusyCiGSQoh+sCzkQQAOCZCjTmUkotMBbBRCzFAXB8hQX/d5iBDiCACnAriWiIYGbFsfMiZguTCfEEL0B7AblpvDj3q5jvbYyRkAXs60qWFZwemhYlPuawF0Vr53AvB1PcliYgMRtQcA+/9Ge3m9yE1EJbAU+7+FEK8VoowSIcQ2AB/D8mG2ICKZ1E6Vw5HRXt8cwNZaFGsIgDPIKhD/IizXzCMFJB8A33oLhXSf1wJYK4SYZn9/BZayLyQZAatx/FIIscH+XmjyZUWxKfcvAPSwoxVKYXWh3qxnmVTeBPBj+/OPYfm55fJL7FH2owBsl9292oKICMDTABYKIR4qUBnbElEL+3MjACcCWAjgIwDn+sgoZT8XwIfCdnrWBkKIW4UQnYQQXWE9ax8KIS4qFPmAwHoLBXOfhRDrAawhol72ohEAFhSSjDYXIO2SkXIUknzZUd9O/xwGPEbBivxYDuC2epTjBQDfAKiG1ZJfDsu/+gGApfb/Vva2BOAxW+a5AAbUgXzHwuoqzgEwy/4bVWAy9gUw05ZxHoDf2su7A/gcwDJYXeQye3m5/X2Zvb57Hd7v45GOlikY+WxZZtt/8+U7UUj32T5uPwDT7Xv9OoCWhSQjrAH9LQCaK8sKRr5c/niGKsMwTAOk2NwyDMMwTAhYuTMMwzRAWLkzDMM0QFi5MwzDNEBYuTMMwzRAWLkzDMM0QFi5MwzDNEBYuTMMwzRA/h/2yxid2rTqRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.2).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained we will save it, we can use it in the future to make predictions. We need to save the encoder, the decoder and the input and output vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), './enc.w')\n",
    "torch.save(attn_decoder1.state_dict(), './att.w')\n",
    "# Save the vocabularies\n",
    "input_lang.save_to_file('input_vocab.pkl')\n",
    "output_lang.save_to_file('output_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vocabularies, \n",
    "#input_vocab= load_vocab('input_vocab.pkl')\n",
    "#output_vocab= load_vocab('output_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and execute if you want to show some results quickly\n",
    "#evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "We predict the summary for every text in our validation dataset and then we can compare them to the targeted summary. We also calculate the Rouge metrics and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = valid_dataset['text'].values\n",
    "y_test = valid_dataset['summary'].values\n",
    "# Generate the predctions on the validation dataset\n",
    "predicted_summaries = generate_predictions(x_test, encoder1, attn_decoder1, input_lang, output_lang, MAX_LENGTH, 100)\n",
    "# Set teh labeled summaries as the y_test variable, column summary of our dataset\n",
    "labeled_summaries = y_test\n",
    "#print(len(x_test), len(labeled_summaries), len(predicted_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pred:  man man found found found \n",
      " Target:  mika singh daler mehndis elder brother amarjeet passes away\n",
      "\n",
      " Pred:  man man found dead \n",
      " Target:  sunfeast farmlite made aashirvaad atta 0 maida\n",
      "\n",
      " Pred:  man kapoor shares pic \n",
      " Target:  take tremendous pride woman colour priyanka\n",
      "\n",
      " Pred:  delhi police arrested delhi delhi \n",
      " Target:  swine flu toll rises 17 odisha\n",
      "\n",
      " Pred:  india bans pak pak pak \n",
      " Target:  rafale aircraft capable waiting iaf vice chief\n"
     ]
    }
   ],
   "source": [
    "print('\\n Pred: ',predicted_summaries[100],'\\n Target: ', labeled_summaries[100])\n",
    "print('\\n Pred: ',predicted_summaries[200],'\\n Target: ', labeled_summaries[200])\n",
    "print('\\n Pred: ',predicted_summaries[300],'\\n Target: ', labeled_summaries[300])\n",
    "print('\\n Pred: ',predicted_summaries[400],'\\n Target: ', labeled_summaries[400])\n",
    "print('\\n Pred: ',predicted_summaries[500],'\\n Target: ', labeled_summaries[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets evaluate with the ROUGE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_textfile(filename, strings):\n",
    "    ''' Save the contect of a list of strings to a file called filename\n",
    "    \n",
    "        Input:\n",
    "           - filename: name of the file to save the strings\n",
    "           - strings: a list of string to save to disk\n",
    "    '''\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        for item in strings:\n",
    "            #Remove any \\n in the string\n",
    "            item = remove_CTL(item)\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "def eval_metrics(preds, targets, avg=True):\n",
    "    ''' Evaluate the ROUGE metrics ROUGE-2 and ROUGE-L for every pair predicted summary - target summary\n",
    "    \n",
    "        Input:\n",
    "           - preds: list of strings, predicted summaries\n",
    "           - targets: list of string, target summaries\n",
    "        Output:\n",
    "            - rouge2_f_metric: list of float, the Rouge-2 fscore for every predicted summary\n",
    "            - rougel_f_metric: list of float, the Rouge-L fscore for every predicted summary\n",
    "    '''\n",
    "    #Lets calculate the rouge metrics for every document\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(preds, targets, avg)\n",
    "    # Create the output variables\n",
    "    if avg:\n",
    "        rouge2_f_metric = scores['rouge-2']['f']\n",
    "        rouge2_p_metric = scores['rouge-2']['p']\n",
    "        rouge2_r_metric = scores['rouge-2']['r']\n",
    "        rougel_f_metric = scores['rouge-l']['f']\n",
    "        rougel_p_metric = scores['rouge-l']['p']\n",
    "        rougel_r_metric = scores['rouge-l']['r']\n",
    "    else:\n",
    "        rouge2_f_metric = [score['rouge-2']['f'] for score in scores]\n",
    "        rouge2_p_metric = [score['rouge-2']['p'] for score in scores]\n",
    "        rouge2_r_metric = [score['rouge-2']['r'] for score in scores]\n",
    "        rougel_f_metric = [score['rouge-l']['f'] for score in scores]\n",
    "        rougel_p_metric = [score['rouge-l']['p'] for score in scores]\n",
    "        rougel_r_metric = [score['rouge-l']['r'] for score in scores]\n",
    "\n",
    "       \n",
    "    \n",
    "    return rouge2_f_metric, rouge2_p_metric, rouge2_r_metric, rougel_f_metric, rougel_p_metric, rougel_r_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the Rouge-2 and Rouge-L metrics for the validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rouge-2 FScore:  0.004118184491251278 Mean Rouge-L FScore:  0.06175245430535315\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Rouge-2 and Rouge-L metrics for the validation dataset\n",
    "r2_f, r2_p, r2_r, rl_f, rl_p, rl_r = eval_metrics(predicted_summaries, list(labeled_summaries), False)\n",
    "print('Mean Rouge-2 FScore: ',np.mean(r2_f), 'Mean Rouge-L FScore: ',np.mean(rl_f))\n",
    "#Store the results on the dataframe\n",
    "valid_dataset['pred_summary'] = predicted_summaries\n",
    "valid_dataset['rouge2-f'] = r2_f\n",
    "valid_dataset['rouge2-p'] = r2_p\n",
    "valid_dataset['rouge2-r'] = r2_r\n",
    "valid_dataset['rougel-f'] = rl_f\n",
    "valid_dataset['rougel-p'] = rl_p\n",
    "valid_dataset['rougel-r'] = rl_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>rouge2-f</th>\n",
       "      <th>rouge2-p</th>\n",
       "      <th>rouge2-r</th>\n",
       "      <th>rougel-f</th>\n",
       "      <th>rougel-p</th>\n",
       "      <th>rougel-r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>paytm raises 1 4 billion softbank largest funding</td>\n",
       "      <td>digital payments startup paytm raised 1 4 bill...</td>\n",
       "      <td>startup startup startup raises raises raises</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>petrol price cut per litre daily revision starts</td>\n",
       "      <td>oil companies thursday reduced petrol price di...</td>\n",
       "      <td>india india india india india</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>army plans deploy women officers cyber warfare</td>\n",
       "      <td>indian army announced plans deploy women offic...</td>\n",
       "      <td>amazon killed 2 lakh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>uday chopra confirms yrf produce jessica chast...</td>\n",
       "      <td>yash raj films ceo uday chopra confirmed los a...</td>\n",
       "      <td>new bans take new</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mulayam yadav contest 2019 polls mainpuri sp l...</td>\n",
       "      <td>senior samajwadi party leader ram gopal yadav ...</td>\n",
       "      <td>bjp bjp bjp bjp bjp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  paytm raises 1 4 billion softbank largest funding   \n",
       "1   petrol price cut per litre daily revision starts   \n",
       "2     army plans deploy women officers cyber warfare   \n",
       "3  uday chopra confirms yrf produce jessica chast...   \n",
       "4  mulayam yadav contest 2019 polls mainpuri sp l...   \n",
       "\n",
       "                                                text  \\\n",
       "0  digital payments startup paytm raised 1 4 bill...   \n",
       "1  oil companies thursday reduced petrol price di...   \n",
       "2  indian army announced plans deploy women offic...   \n",
       "3  yash raj films ceo uday chopra confirmed los a...   \n",
       "4  senior samajwadi party leader ram gopal yadav ...   \n",
       "\n",
       "                                   pred_summary  rouge2-f  rouge2-p  rouge2-r  \\\n",
       "0  startup startup startup raises raises raises       0.0       0.0       0.0   \n",
       "1                 india india india india india       0.0       0.0       0.0   \n",
       "2                          amazon killed 2 lakh       0.0       0.0       0.0   \n",
       "3                             new bans take new       0.0       0.0       0.0   \n",
       "4                           bjp bjp bjp bjp bjp       0.0       0.0       0.0   \n",
       "\n",
       "   rougel-f  rougel-p  rougel-r  \n",
       "0       0.2       0.5     0.125  \n",
       "1       0.0       0.0     0.000  \n",
       "2       0.0       0.0     0.000  \n",
       "3       0.0       0.0     0.000  \n",
       "4       0.0       0.0     0.000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.to_csv('results.csv', index=False)\n",
    "valid_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "\n",
    "We are going to plotting the distribution of the Rouge-2 and Rouge-L values in the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0572dda4a8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "kwargs = dict(hist_kws={'alpha':.7}, kde_kws={'linewidth':2})\n",
    "# plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=False, dpi=100)\n",
    "sns.distplot(valid_dataset['rouge2-f'] , color=\"dodgerblue\", ax=axes[0], axlabel='Rouge-2 Fscore')\n",
    "sns.distplot(valid_dataset['rougel-f'], color=\"deeppink\", ax=axes[1], axlabel='Rouge-L Fscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
